from google import genai
from google.genai import types
from datetime import datetime

client = genai.Client(api_key="Insert your API key here") #Logging into the API (the api_key string is a unique key given to each account)
#You API key can be tied directly to your account, so it is important to keep it secure. If you suspect that it has been compromised, you can regenerate it in the API settings of your account.
#All requests to the API are tracked!! and charged to the account of the user. The API is a paid service, so be careful with how you use it. The cost of a request is based on the number of tokens generated by the AI.

#These variables are used to configure the AI's response:
max_tokens = 10e6
temp = 0.95
topk = 50
topp = .7
candidates = 1

safety_settings = [ #Safety settings for the AI
    {
        "category": types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        "threshold": types.HarmBlockThreshold.BLOCK_NONE
        #Note that the threshold can be set to BLOCK_NONE, BLOCK_ONLY_HIGH, BLOCK_MEDIUM_AND_ABOVE, BLOCK_LOW_AND_ABOVE
        #Note that the categories are HARM_CATEGORY_HATE_SPEECH, HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_DANGEROUS_CONTENT
    },
    {
        "category": types.HarmCategory.HARM_CATEGORY_HARASSMENT,
        "threshold": types.HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        "threshold": types.HarmBlockThreshold.BLOCK_NONE
    },
    {
        "category": types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        "threshold": types.HarmBlockThreshold.BLOCK_NONE
    }
]

#Initializing the chat history / log of the conversation:
chat_history = "" 
chat_history += f"Generation Configuration:\n"
chat_history += f"max_tokens: {max_tokens}\n"
chat_history += f"temperature: {temp}\n"
chat_history += f"top_p: {topp}\n"
chat_history += f"top_p: {topk}\n"
chat_history += f"candidate_count: {candidates}\n"
chat_history += f"-----------------------\n"

def write_string_to_file(filename, text_string): # This function writes a string to a text file
    try:
        with open (filename, 'w') as file:
            file.write(text_string)
            print(f"Successfully wrote the text to '{filename}'")
    except Exception as e:
        print(f"An error occurred: {e}")    

def read_file_contents(file_path): # This function reads the contents of a text file and returns it as a string
    """
    Reads the contents of a text file and returns it as a string.
    
    Parameters:
    file_path (str): The path to the text file.
    
    Returns:
    str: The contents of the text file.
    """
    with open(file_path, 'r') as file:
        file_contents = file.read()
    return file_contents

context = "" #Ideally this would be where you'd store any text information that you want the AI to have access to in order to reference.
#context += read_file_contents(file name here)

times_run = 0 #Setting a counter to keep track of the number of times the AI has been run. This helps with formatting the chat_history

while 1 < 2: #Running an infinite loop to keep the chat session going

    current_datetime = datetime.now()
    datetime_string = "Year"+str(current_datetime.year) +"_Month"+ str(current_datetime.month) +"_Day"+ str(current_datetime.day) +"_Hour"+ str(current_datetime.hour) +"_Minute"+ str(current_datetime.minute) +"_Second"+ str(current_datetime.second)
    #^^Updating the datetime string for each run of the AI

    get_prompt = input("\n \nINPUT YOUR PROMPT: ")
    user_prompt = get_prompt + f"\n \n Note that the history of this chat session is: {chat_history}" + f"\n \n Note that the context associated with this chat session is: {context}"
   
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=user_prompt,
        config=types.GenerateContentConfig(
            #PLEASE DO NOT CHANGE THESE VALUES HERE, CHANGE THESE VALUES IN THE VARIABLES AT THE TOP OF THE SCRIPT
            max_output_tokens = max_tokens,#This is the maximum number of tokens that the AI will generate. The AI will stop generating tokens once it reaches this limit.
            
            temperature = temp, #This is the randomness of the AI's responses. 0 is deterministic, 1 is very random
            
            top_k = topk, #This is the number of tokens that the AI considers when generating a response. A higher value will make the AI more creative/random as it gives itself more tokens to choose from, a low value will make it more predictable (better for technical writing, report writing, etc.)
            
            top_p = topp, #This is the cumulative probability of the AI's top choices. It is a float between 0 and 1
            #top_p limits the set of potential tokens to the smallest subset whose cumulative probability is greater than or equal to p. So if you set top_p to 0.9, the AI will consider the most likely tokens until their cumulative probability is 0.9. This is a good way to control the randomness of the AI's responses.
            
            candidate_count = candidates, #Number of responses that the AI generates. The AI will generate this many responses and return the best one. The alternative responses will be stored in response.candidates, w/ each candidate being an object that has its token count, safety rating, and finish_reason.
        
            safety_settings=safety_settings,
        )
    )

    print("\n \n"+response.text)
    chat_history += f"INPUT {times_run}: {get_prompt} \n \nRESPONSE {times_run}: {response.text} \n \n"
    
    to_txt_file = input("Would you like to write the chat history to a text file? (y/n) ")
    if to_txt_file.lower() == "y":
        #input_output = "INPUT: \n" + user_prompt + "\n \n \n" + "OUTPUT: \n" + response.text
        write_string_to_file("Gemini_AI_session "+f" {datetime_string}"+".txt", chat_history)# This writes the output of the AI to a text file]
        # If "AI_output.txt" does not exist, it will be created. If it does exist, it will be overwritten.
    times_run += 1

    






















